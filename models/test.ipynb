{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def mdn_negative_log_likelihood(pi, mu, sigma, target):\n",
    "    \"\"\" Use torch.logsumexp for more stable training \n",
    "    \n",
    "    This is equivalent to the mdn_loss but computed in a numerically stable way\n",
    "\n",
    "    \"\"\"\n",
    "    target = target.unsqueeze(2).expand_as(sigma)\n",
    "    neg_logprob = -torch.log(sigma) - (math.log(2 * math.pi) / 2) - \\\n",
    "        ((target - mu) / sigma)**2 / 2\n",
    "    \n",
    "    # (B, num_heads, num_gaussians)\n",
    "    inner = torch.log(pi) + torch.sum(neg_logprob, 3) # Sum the log probabilities of (x, y) for each 2D Gaussian\n",
    "\n",
    "    print(inner.shape)\n",
    "    return -torch.logsumexp(inner, dim=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2])\n",
      "tensor([[1.9220, 1.9220],\n",
      "        [2.5425, 2.6793]])\n"
     ]
    }
   ],
   "source": [
    "pi = torch.tensor([[[0.9, 0.05, 0.05], \n",
    "                   [0.05, 0.05, 0.9]], \n",
    "                   \n",
    "                   [[0.1, 0.2, 0.7], \n",
    "                   [0.7, 0.1, 0.2]]]) # B, num_heads, n_gaussians\n",
    "\n",
    "\n",
    "mu = torch.tensor([[[1.0, -1.0], [2.0, -2.0], [3, -3]], [[1.0, -1.0], [2.0, -2.0], [3, -3]]]) # B x n_gaussians x 2\n",
    "sigma = torch.tensor([[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]], [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]])\n",
    "\n",
    "# mu_2 = torch.randn((2, 2, 3, 2))\n",
    "# sigma_2 = torch.randn((2, 2, 3, 2))\n",
    "\n",
    "\n",
    "# print(pi.shape)\n",
    "# print(mu.shape)\n",
    "mu_2 = mu.repeat(2, 1, 1, 1) # B x num_heads, n_gaussians, 2\n",
    "sigma_2 = sigma.repeat(2, 1, 1, 1) # B x num_heads, n_gaussians, 2\n",
    "\n",
    "\n",
    "target = torch.randn((2, 2, 2))\n",
    "target = torch.tensor([[[1.0, -1.0],\n",
    "         [3, -3]],\n",
    "\n",
    "        [[2.0,  -2.0],\n",
    "         [ 2.0, -2.0]]])\n",
    "# print(target)\n",
    "\n",
    "\n",
    "res = mdn_negative_log_likelihood(pi, mu_2, sigma_2, target)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "# print(mu_2)\n",
    "# print(mu_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result tensor([[0.1340, 0.2358],\n",
      "        [0.4137, 0.6707]])\n",
      "vectorized tensor([[0.1340, 0.2358],\n",
      "        [0.4137, 0.6707]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "\n",
    "pi = torch.tensor([[0.9, 0.07, 0.03],\n",
    "                #    [0.05, 0.05, 0.9]], \n",
    "                   \n",
    "                #    [[0.1, 0.2, 0.7], \n",
    "                   [0.7, 0.1, 0.2]]) # B, n_gaussians\n",
    "\n",
    "\n",
    "mu = torch.tensor([[[1.0, -1.0], [2.0, -2.0], [3, -3]], [[1.0, -1.0], [2.0, -2.0], [3, -3]]]) # B x n_gaussians x 2\n",
    "sigma = torch.tensor([[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]], [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]])\n",
    "\n",
    "# print(sigma.shape)\n",
    "\n",
    "mu_2 = torch.randn((2, 3, 2))\n",
    "sigma_2 = torch.rand((2, 3, 2)) + 1\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# print(sigma_2.shape)\n",
    "\n",
    "def kl_gaussian(mean_1, sigma_1, mean_2, sigma_2):\n",
    "    \"\"\"\n",
    "    KL divergence between two Gaussian distributions\n",
    "    \"\"\"\n",
    "    var_2 = sigma_2**2\n",
    "    var_1 = sigma_1**2\n",
    "    return torch.log(sigma_2 / sigma_1) + (var_2 + (mean_1 - mean_2) ** 2) / (2*var_2) - 0.5\n",
    "\n",
    "def kl_between_gaussian_mixtures(mix_1, mix_2):\n",
    "\n",
    "    pi_a, mu_a, sigma_a = mix_1 # B x n_gaussians x 2\n",
    "    pi_b, mu_b, sigma_b = mix_2\n",
    "\n",
    "    n_gaussians = mu_b.shape[1]\n",
    "    kl_all = []\n",
    "    for a in range(n_gaussians):\n",
    "\n",
    "        kl_num = []\n",
    "        for a_p in range(n_gaussians):\n",
    "            p_dist = Normal(mu_a[:, a, :], sigma_a[:, a, :])\n",
    "            q_dist = Normal(mu_a[:, a_p, :], sigma_a[:, a_p, :])\n",
    "            kl_n = kl_divergence(p_dist, q_dist)\n",
    "            pi = pi_a[:, a_p]\n",
    "            kl_num.append(torch.einsum('b, bd -> bd', pi, torch.exp(-kl_n)))\n",
    "\n",
    "        kl_num = torch.stack(kl_num) # num_gaussians x 2\n",
    "        kl_num = kl_num.sum(dim=0)\n",
    "        # print(kl_num)\n",
    "        kl_den = []\n",
    "        for b_p in range(n_gaussians):\n",
    "            p_dist = Normal(mu_a[:, a, :], sigma_a[:, a, :]) # b x 2\n",
    "            q_dist = Normal(mu_b[:, b_p, :], sigma_b[:, b_p, :])\n",
    "            kl_d = kl_divergence(p_dist, q_dist)\n",
    "            pi = pi_b[:, b_p]\n",
    "            kl_den.append(torch.einsum('b, bd -> bd', pi, torch.exp(-kl_d)))\n",
    "\n",
    "        kl_den = torch.stack(kl_den) # num_gaussians x 2\n",
    "        kl_den = kl_den.sum(dim=0)\n",
    "        kl_all.append(kl_num / kl_den)\n",
    "        # print(kl_num/kl_den)\n",
    "\n",
    "    # print(kl_all)\n",
    "    kl_all = torch.log(torch.stack(kl_all)) # num_gaussians x b x dimension\n",
    "    # print(kl_all, pi_a)\n",
    "    res = torch.einsum('gbd,bg->gbd', kl_all, pi_a)\n",
    "    # print(res)\n",
    "    return torch.sum(res, dim=0)\n",
    "\n",
    "\n",
    "def kl_gaussian_mixtures_vectorized(mix_1, mix_2):\n",
    "    pi_a, mu_a, sigma_a = mix_1 # B x n_gaussians x 2\n",
    "    pi_b, mu_b, sigma_b = mix_2\n",
    "    n_gaussians = mu_b.shape[1]\n",
    "\n",
    "    # outer\n",
    "    mu_a_tog = torch.repeat_interleave(mu_a, n_gaussians, dim=1) # [a, b, c] --> [a, a, b, b, c, c]\n",
    "    sigma_a_tog = torch.repeat_interleave(sigma_a, n_gaussians, dim=1)\n",
    "\n",
    "    pi_a_p = pi_a.repeat(1, n_gaussians) # B x n_gaussians**2 [a, b, c] --> [a, b, c, a, b, c]\n",
    "    mu_a_p = mu_a.repeat(1, n_gaussians, 1) # B x n_gaussians**2 x 2\n",
    "    sigma_a_p = sigma_a.repeat(1, n_gaussians, 1) # B x n_gaussians**2 x 2\n",
    "\n",
    "    pi_b_p = pi_b.repeat(1, n_gaussians) # B x n_gaussians**2\n",
    "    mu_b_p = mu_b.repeat(1, n_gaussians, 1) # B x n_gaussians**2 x 2\n",
    "    sigma_b_p = sigma_b.repeat(1, n_gaussians, 1) # B x n_gaussians**2 x 2\n",
    "\n",
    "    p_num = Normal(mu_a_tog, sigma_a_tog)\n",
    "    q_num = Normal(mu_a_p, sigma_a_p)\n",
    "    kl_num = kl_divergence(p_num, q_num)\n",
    "    # print(kl_num)\n",
    "\n",
    "    kls_num = torch.einsum('bxd,bx->bxd', torch.exp(-kl_num), pi_a_p) # B x n_gaussians**2\n",
    "    kls_num_reshaped = kls_num.reshape(kl_num.shape[0], n_gaussians, n_gaussians, 2) # B x n_gaussians x n_gaussians x 2\n",
    "    num = kls_num_reshaped.sum(dim=2) # B x n_gaussians x 2\n",
    "\n",
    "    p_den = Normal(mu_a_tog, sigma_a_tog)\n",
    "    q_den = Normal(mu_b_p, sigma_b_p)\n",
    "    kl_den = kl_divergence(p_den, q_den)\n",
    "    kls_den = torch.einsum('bxd,bx->bxd', torch.exp(-kl_den), pi_b_p) # B x n_gaussians**2\n",
    "    kls_den_reshaped = kls_den.reshape(kl_den.shape[0], n_gaussians, n_gaussians, 2) # B x n_gaussians x n_gaussians x 2\n",
    "    den = kls_den_reshaped.sum(dim=2) # B x n_gaussians x 2\n",
    "\n",
    "    divided = num / den # B x num_gaussians x 2\n",
    "    # print(divided.shape)\n",
    "    res = torch.einsum('bgd,bg->bgd', torch.log(divided), pi_a)\n",
    "    return res.sum(dim=1)\n",
    "\n",
    "res = kl_between_gaussian_mixtures((pi, mu, sigma), (pi, mu_2, sigma_2))\n",
    "# res = kl_between_gaussian_mixtures((pi, mu_2, sigma_2), (pi, mu_2, sigma_2))\n",
    "print(\"result\", res)\n",
    "\n",
    "# print(res)\n",
    "vectorized = kl_gaussian_mixtures_vectorized((pi, mu, sigma), (pi, mu_2, sigma_2))\n",
    "# vectorized = kl_gaussian_mixtures_vectorized((pi, mu_2, sigma_2), (pi, mu_2, sigma_2))\n",
    "print(\"vectorized\", vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [2, 2]])\n",
      "tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 1, 2, 2])\n",
    "b =a.reshape(2, 2)\n",
    "print(b)\n",
    "print(b.sum(dim=1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c3bfbc0528239c32ebf5b583237c33afb2ab3d4f242283158514eeade34da9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('prisoner_auto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
